# Chapter 3 - Logistic Regression 

*Describe the work you have done this week and summarize your learning.*

```{r}
date()
```



```{r}
library(ggplot2)
library(GGally)
library(dplyr)

alc<-read.table("https://github.com/rsund/IODS-project/raw/master/data/alc.csv",header = T, sep = ",")
# alc<-read.table("data/alc.csv",header = T, sep = ";")
colnames(alc)
```

This data is the result of data wrangling exercise (though I loaded the orignal online source to be sure I have 100% start point). It includes students' math (G1-3.m) and Portuguese (G1-3.p) final class grades, together with alcohol use, gender and social factors, such as class absences, family support, etc. Full info of variable meanings can be found here: https://archive.ics.uci.edu/ml/datasets/Student+Performance


The 4 variables of interest for me to be studied in relation to alcohol use were: 
gender of subjects (sex) 
number of past class failures (failures) 0-3, 4 if more 
quality of family relationships (famrel) from 1 - very bad to 5 - excellent
number of school absences (absences) from 0 to 93 

My initial prediction is that males use on average more alcohol than females, students who have high number of past class failures and absences use more alcohol, and those who have better family relationships use less alcohol on average.  

making subset of data.frame, that includes only the studied variables:


```{r}
alc_study<-subset(alc, select = c(high_use, alc_use, sex, failures, famrel, absences))

alc %>% group_by(sex) %>% summarise(count = n())

alc %>% group_by(absences) %>% summarise(count = n())

alc %>% group_by(failures) %>% summarise(count = n())

alc %>% group_by(famrel) %>% summarise(count = n())

(p <- ggpairs(alc_study, mapping = aes(col = sex, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20))))
```

Based on the summaries and graphs the initial predictions were fairly correct: males drink more alcohol on average, absences and failures have positive correlation with alcohol use whereas the famrel has negative correlation.

## Logistic regression model

Here I use logistic regression model to study the factors' relationships with high alcohol usage


```{r}
# find the model with glm()
m <- glm(high_use ~ failures + absences + sex + famrel, data = alc, family = "binomial")

# print out a summary of the model
summary(m)

# print out the coefficients of the model
coef(m)

 coef(m) %>% exp
```
 

failures (OR=1.77), absences (OR=1.09) and male sex (OR=2.85) have odds ratio above 1 for high alcohol use, which means they increase the risk for high alcohol use, i.e. makes are at 185% more risk for high alcohol usage than females. THe famrel (good family relations, OR=0.74) in turn has odds ratio below 1, which means good students with family relation have are reduced risk of high alcohol use.

All four variables have at least nominally significant P-values (P<0.05).

The odds ratios support the predictions and correlations I made before. 

## Model performance

Here I test model performance with crosstabs and loss function: 

```{r}

# predict() the probability of high_use
probabilities <- predict(m, type = "response")

# add the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)

# use the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = (probabilities > 0.5))

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction)

p1 <- ggplot(alc, aes(x = probability, y = high_use, col = prediction))
p1 + geom_point()


# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# call loss_func to compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = 0)



```
The loss function 0.3 means model makes mistake in 30% of predictions (and succeeds in 70%). Since random choices would have 50% chance of success in binary classification, this model performs significantly better.

## 10-fold cross-validation

Here I perform 10-fold cross-validation for my model.

```{r}

# K-fold cross-validation
library(boot)

cv <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)

# average number of wrong predictions in the cross validation
cv$delta[1]

```
My model had 0.25 error, which is slightly better than DataCamp model's error of 0.26. My model is very similar to DataCamp's, and it only includes 1 extra variable (famrel), which seems to only slightly improve the model performance.
